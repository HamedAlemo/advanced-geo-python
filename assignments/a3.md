# Assignment 3

The goal of this assignment is to query a STAC API and find satellite imagery given some search parameters. Then use `stackstac` to retrieve a large set of data and calculate NDWI values.

You should submit this assignment to your existing `geog313-assignments` GitHub repository under a new directory named `assignment-3`. Your notebooks should be able to run on Microsoft Planetary Computer (PC) Hub. In the instructions for your code, provide guidance how  users should use your notebook within this hub. 

*Note*: As you know, the Python environment within the PC Hub can change, so you need to note the version of all packages you are using in your notebook in the documentation so anyone can reproduce your results. 

## Search for Satellite Imagery

For this part, you will use the Earth Search STAC API available at: `https://earth-search.aws.element84.com/v1`. Develop a Jupyter Notebook (name it `s2_query.ipynb`) that implements the following using this API:

1. Connects to the API and prints out the `title` property of all the available collections. 
2. Retrieves the number of scenes from `sentinel-2-l2a` collection that intersects with the following point, and are acquired between *Jan 1st, 2022 and May 31st, 2022*: 

    `point_of_interest_latitude = 11.232754`

    `point_of_interest_longitude = 35.004162`

3. Plots a histogram of the percent water present in each scene across all the scenes from the step 2 query. (water classification is recorded in the `s2:water_percentage` property in the STAC catalog)
4. Returns the `id` of all scenes that follow the query parameters identified in step 2, and have less than 5% pixels covered by cloud and more than 50% of the pixels classified as water.

## Retrieve NDWI Time Series

For this part, you will use the same Earth Search STAC API but retrieve pixel values to calculate NDWI across time. Develop a Jupyter Notebook (name it `ndwi_unfiltered.ipynb`) that implements the following using this API:

1. Starts a local Dask cluster. 
2. Searches the API for Sentinel-2 surface reflectance scenes between *Jan 1st, 2017 and Dec 31st, 2022* across the following bbox that have a cloud cover of less than 50%:

    `bbox = (35.16402630997399, 11.240162235950265, 35.17440912681519, 11.249823496541282)`

3. Uses `stackstac` to retrieve bands B03 (Green) and B08 (NIR) from the scenes found in step 2. 
4. Calculates NDWI for all pixels within the bbox for each scene from step 2. 
5. Calculates the mean NDWI across all pixels within the bbox at each time. 
6. Generates a figure and plots mean NDWI values from step 5 vs time.

All of the steps above should be carried out using Dask lazy computation until step 6 that the plot will be generated. 


## Filter NDWI Time Series

We know that some pixels from our previous NDWI calculation will be cloudy, and have an incorrect NDWI value. In this part, you will revise the Jupyter Notebook from the previous section and filter cloudy pixels. Name your new Jupyter Notebook `ndwi_filtered.ipynb` and do the following:

1. Revise your `ndwi_unfiltered.ipynb` notebook to retrieve the same scenes, but also retrieve the Scene Classification (SCL) band from Sentinel-2. 
2. Before plotting your NDWI time series, filter cloudy pixels based on SCL value, and exclude them from the plot. (checkout the table in Figure 3 [here](https://sentinels.copernicus.eu/web/sentinel/technical-guides/sentinel-2-msi/level-2a/algorithm-overview) to learn about different values in the SCL layer. You need to exclude any pixel that has a SCL value of 3, 8, 9 or 10)

Similar to the previous section, all your calculations, including the cloud filtering should be carried out using lazy computation until the plot generation step. 


